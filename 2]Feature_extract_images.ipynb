{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2]Feature_extract_images.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6ghZQMCp1rXSy5dGszS1p"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "53FT3gBoVtAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extracting features from images. Computer vision is a study and design of computational artifacts that process and understand images.\n",
        "#we will review some basic techniques used in computer vision to represent images in ML problems."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A4esXzOWMdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "aed3290e-2aa6-48bd-cf77-35c94dc78072"
      },
      "source": [
        "#Extracting features from pixel intensities\n",
        "#1.Let's use OCR(Optical Character Recognition) to create basic feature representations that could be used in an OCR application for recognizing\n",
        "#handwritten digits. Each Pixel has intensity value between 0 and 16. White being the most intense i.e and black being the least i.e 16\n",
        "#code\n",
        "from sklearn import datasets\n",
        "digits=datasets.load_digits()\n",
        "#printing the first target value\n",
        "print(\"First Digit\",digits.target[0])\n",
        "#print 8*8 matrix of images 0\n",
        "print(\"Image matrix:\",digits.images[0])\n",
        "#Creating feature vector by reshaping the image matrix to 64 dimensional vector\n",
        "print(\"Feature vector:\",digits.images[0].reshape(-1,64))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Digit 0\n",
            "Image matrix: [[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
            " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
            " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
            " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
            " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
            " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
            " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
            " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
            "Feature vector: [[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
            "  15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
            "   0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
            "   0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIYMhZaOb3qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#conclusion: This representation can be effective for some basic task such as recognizing printed characters.\n",
        "#However, recording the intensity of every pixel in the image produces large feature fectors and increases the space complexity.\n",
        "#Moreover, learning from intensities of pixel at particular locations results in models that are sensitive to changes in scale,rotation\n",
        "#and translation of images\n",
        "#A model trained on our basic feature representations might not be able to recognize the same zero if it shifted in any direction,rotated\n",
        "#or enlarged."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}