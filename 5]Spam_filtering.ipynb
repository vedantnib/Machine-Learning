{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5]Spam_filtering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiTgS1QQPhKtLc1jMez1ae",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedantnib/Machine-Learning/blob/master/5%5DSpam_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szyWjuq2yuhS",
        "colab_type": "text"
      },
      "source": [
        "We will classify spam and ham sms. We will extract TF-IDF features from the messages using techniques learned in feature extraction and processing, and classify the messages using logistic regression.\n",
        "We will use SMS Spam Classificaation Data Set from UCI ML Repository. The link for the same is : https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E7nuGR3LwPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "83200b7f-4738-4b19-ea7c-094a88455aed"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/SMSSpamCollection', delimiter='\\t',header=None)\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      0                                                  1\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akWeBULBzZ4f",
        "colab_type": "text"
      },
      "source": [
        "The ham messages are labelled with 0 and the spam messages are labelled with 1. Inspecting the data may reveal other attributes that should be captured in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTH3e2SrRFTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "398bfac2-4cb8-46ad-b779-cbd40ef5d8f8"
      },
      "source": [
        "print(\"Spam messages: \",df[df=='spam'][0].count())\n",
        "print(\"Ham messages: \",df[df=='ham'][0].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam messages:  747\n",
            "Ham messages:  4825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ideVUACWzxjg",
        "colab_type": "text"
      },
      "source": [
        "Let's make some predictions using sklearn's LogisticRegression class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmjn3BJ_RG3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "84e4b065-ce09-4bf4-eb8a-07ab91a4c92c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model.logistic import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "#previously train_test_split,cross_val_score were under cross_validation, but are now under model_selection\n",
        "\n",
        "df=pd.read_csv('/content/SMSSpamCollection', delimiter='\\t',header=None)\n",
        "#train_test_split assigns 75% data to training set and 25% to test set by default\n",
        "#in the argument of function train_test_split(), we put df[1] i.e the message first because we assign it\n",
        "# X-axis as it is our explanatory variable and df[0] i.e 'spam/ham' to Y-axis as it is our response variable\n",
        "X_train_raw,X_test_raw,y_train,y_test=train_test_split(df[1],df[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NE1QMv1z_EE",
        "colab_type": "text"
      },
      "source": [
        "Next we create a TfidVectorizer. We fit training messages, and transform both the training and test messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNrvLNb7TyfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer=TfidfVectorizer()\n",
        "X_train=vectorizer.fit_transform(X_train_raw)\n",
        "X_test=vectorizer.transform(X_test_raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KcKMUIn0KSA",
        "colab_type": "text"
      },
      "source": [
        "Finally, we create an instance of LogisticRegression and train our model. Like LinearRegression, LogisticRegression implements the fit() and predict() methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoK1ZMDMV6Bw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "3eef79d2-729e-4265-dd69-a6db2fec5bf5"
      },
      "source": [
        "classifier=LogisticRegression()\n",
        "classifier.fit(X_train,y_train)\n",
        "predictions=classifier.predict(X_test)\n",
        "for i,prediction in zip(X_test_raw[:50],predictions[:50]):\n",
        "  print (\"Prediction: %s, Message: %s \" %(prediction, i))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: ham, Message: We took hooch for a walk toaday and i fell over! Splat! Grazed my knees and everything! Should have stayed at home! See you tomorrow!  \n",
            "Prediction: ham, Message: Now only i reached home. . . I am very tired now. . I will come tomorro \n",
            "Prediction: ham, Message: Storming msg: Wen u lift d phne, u say \"HELLO\" Do u knw wt is d real meaning of HELLO?? . . . It's d name of a girl..! . . . Yes.. And u knw who is dat girl?? \"Margaret Hello\" She is d girlfrnd f Grahmbell who invnted telphone... . . . . Moral:One can 4get d name of a person, bt not his girlfrnd... G o o d n i g h t . . .@ \n",
            "Prediction: ham, Message: I love working from home :) \n",
            "Prediction: ham, Message: Left dessert. U wan me 2 go suntec look 4 u? \n",
            "Prediction: ham, Message: 88800 and 89034 are premium phone services call 08718711108 \n",
            "Prediction: ham, Message: Thanks for being there for me just to talk to on saturday. You are very dear to me. I cherish having you as a brother and role model. \n",
            "Prediction: ham, Message: Man this bus is so so so slow. I think you're gonna get there before me \n",
            "Prediction: spam, Message: Get a brand new mobile phone by being an agent of The Mob! Plus loads more goodies! For more info just text MAT to 87021. \n",
            "Prediction: ham, Message: You are a big chic. Common. Declare \n",
            "Prediction: ham, Message: Ok then i come n pick u at engin? \n",
            "Prediction: ham, Message: Can you open the door? \n",
            "Prediction: ham, Message: Warner Village 83118 C Colin Farrell in SWAT this wkend @Warner Village & get 1 free med. Popcorn!Just show msg+ticket@kiosk.Valid 4-7/12. C t&c @kiosk. Reply SONY 4 mre film offers \n",
            "Prediction: ham, Message: Give me a sec to think think about it \n",
            "Prediction: ham, Message: Good. No swimsuit allowed :) \n",
            "Prediction: ham, Message: Nan sonathaya soladha. Why boss? \n",
            "Prediction: ham, Message: Hey. What happened? U switch off ur cell d whole day. This isnt good. Now if u do care, give me a call tomorrow. \n",
            "Prediction: ham, Message: Nt joking seriously i told \n",
            "Prediction: ham, Message: Er yep sure. Props? \n",
            "Prediction: ham, Message: Wot u up 2 u weirdo? \n",
            "Prediction: ham, Message: Is she replying. Has boye changed his phone number \n",
            "Prediction: ham, Message: Mm that time you dont like fun \n",
            "Prediction: ham, Message: Reminder: You have not downloaded the content you have already paid for. Goto http://doit. mymoby. tv/ to collect your content. \n",
            "Prediction: ham, Message: 7 wonders in My WORLD 7th You 6th Ur style 5th Ur smile 4th Ur Personality 3rd Ur Nature 2nd Ur SMS and 1st \"Ur Lovely Friendship\"... good morning dear \n",
            "Prediction: spam, Message: T-Mobile customer you may now claim your FREE CAMERA PHONE upgrade & a pay & go sim card for your loyalty. Call on 0845 021 3680.Offer ends 28thFeb.T&C's apply \n",
            "Prediction: ham, Message: Watching telugu movie..wat abt u? \n",
            "Prediction: ham, Message: Kind of. Took it to garage. Centre part of exhaust needs replacing. Part ordered n taking it to be fixed tomo morning. \n",
            "Prediction: spam, Message: important information 4 orange user 0789xxxxxxx. today is your lucky day!2find out why log onto http://www.urawinner.com THERE'S A FANTASTIC SURPRISE AWAITING YOU! \n",
            "Prediction: ham, Message: NONE!NOWHERE IKNO DOESDISCOUNT!SHITINNIT \n",
            "Prediction: ham, Message: Waiting in e car 4 my mum lor. U leh? Reach home already? \n",
            "Prediction: ham, Message: Ok i also wan 2 watch e 9 pm show... \n",
            "Prediction: spam, Message: YOU ARE CHOSEN TO RECEIVE A £350 AWARD! Pls call claim number 09066364311 to collect your award which you are selected to receive as a valued mobile customer. \n",
            "Prediction: ham, Message: Lol its ok I didn't remember til last nite \n",
            "Prediction: ham, Message: I taught that Ranjith sir called me. So only i sms like that. Becaus hes verifying about project. Prabu told today so only pa dont mistake me.. \n",
            "Prediction: ham, Message: Storming msg: Wen u lift d phne, u say \"HELLO\" Do u knw wt is d real meaning of HELLO?? . . . It's d name of a girl..! . . . Yes.. And u knw who is dat girl?? \"Margaret Hello\" She is d girlfrnd f Grahmbell who invnted telphone... . . . . Moral:One can 4get d name of a person, bt not his girlfrnd... G o o d n i g h t . . .@ \n",
            "Prediction: ham, Message: Ok then i will come to ur home after half an hour \n",
            "Prediction: ham, Message: S....s...india going to draw the series after many years in south african soil.. \n",
            "Prediction: ham, Message: Since when, which side, any fever, any vomitin. \n",
            "Prediction: ham, Message: Networking technical support associate. \n",
            "Prediction: ham, Message: Friendship poem: Dear O Dear U R Not Near But I Can Hear Dont Get Fear Live With Cheer No More Tear U R Always my Dear. Gud ni8 \n",
            "Prediction: ham, Message: In work now. Going have in few min. \n",
            "Prediction: ham, Message: That day you asked about anand number. Why:-) \n",
            "Prediction: spam, Message: SMS AUCTION - A BRAND NEW Nokia 7250 is up 4 auction today! Auction is FREE 2 join & take part! Txt NOKIA to 86021 now! \n",
            "Prediction: ham, Message: Good evening Sir, Al Salam Wahleykkum.sharing a happy news.By the grace of God, i got an offer from Tayseer,TISSCO and i joined.Hope you are fine.Inshah Allah,meet you sometime.Rakhesh,visitor from India. \n",
            "Prediction: ham, Message: Purity of friendship between two is not about smiling after reading the forwarded message..Its about smiling just by seeing the name. Gud evng \n",
            "Prediction: spam, Message: 4mths half price Orange line rental & latest camera phones 4 FREE. Had your phone 11mths ? Call MobilesDirect free on 08000938767 to update now! or2stoptxt \n",
            "Prediction: ham, Message: Forgot you were working today! Wanna chat, but things are ok so drop me a text when you're free / bored etc and i'll ring. Hope all is well, nose essay and all xx \n",
            "Prediction: ham, Message: Hi Petey!noim ok just wanted 2 chat coz avent spoken 2 u 4 a long time-hope ur doin alrite.have good nit at js love ya am.x \n",
            "Prediction: ham, Message: What time you think you'll have it? Need to know when I should be near campus \n",
            "Prediction: ham, Message: Ya but it cant display internal subs so i gotta extract them \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP_uVD5E0yd6",
        "colab_type": "text"
      },
      "source": [
        "How well does our classifier perform? This performance metrics we used for linear gression are inappropriate for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veRgx2qH1Zfc",
        "colab_type": "text"
      },
      "source": [
        "Let's deviate from the sms spam detection dataset for a while lets focus a and know a bit about ***Binary classification performance metrics.***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrHd_Ye2v4Jz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "d604bdff-3205-4fd3-ef89-104394f86879"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "y_test=[0,0,0,0,0,1,1,1,1,1]\n",
        "y_pred=[0,1,0,0,0,0,0,1,1,1]\n",
        "confusion_matrix=confusion_matrix(y_test,y_pred)\n",
        "print(confusion_matrix)\n",
        "plt.matshow(confusion_matrix)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4 1]\n",
            " [2 3]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em32NmNe3w_2",
        "colab_type": "text"
      },
      "source": [
        "# ***ACCURACY***\n",
        "Accuracy measures a fraction of classifier's predictions that are correct. sklearn provides a function to calculate the accuracy of of the set of predictions given the correct labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tXO-5hk4LjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad5a0072-5d0f-465b-b857-98277335f862"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred,y_true=[0,1,1,0],[1,1,1,1]\n",
        "print(\"Accuracy: \",accuracy_score(y_true,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqVawykY9pDW",
        "colab_type": "text"
      },
      "source": [
        "LogisticRegression.score() predicts scores labels for a test set using accuracy. Let's bring back our ***sms spam dataset*** back into picture and evaluate our classifier's accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSKG5d1B4lMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e6f42cb0-510a-4c60-ed54-e7f179a07c91"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model.logistic import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "#we had imported our csv earlier so no need to import it again. However, in a new notebook or program, you need to import it.\n",
        "X_train_raw,X_test_raw,y_train,y_test=train_test_split(df[1],df[0])\n",
        "vectorizer=TfidfVectorizer()\n",
        "X_train=vectorizer.fit_transform(X_train_raw)\n",
        "X_test=vectorizer.transform(X_test_raw)\n",
        "classifier=LogisticRegression()\n",
        "classifier.fit(X_train,y_train)\n",
        "scores=cross_val_score(classifier,X_train,y_train,cv=7)\n",
        "print(np.mean(scores))\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9569274946159367\n",
            "[0.95309883 0.95309883 0.95812395 0.95979899 0.95979899 0.97152429\n",
            " 0.94304858]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqCyfWCNAJiy",
        "colab_type": "text"
      },
      "source": [
        "Note that accuracy may differ as the training and test sets are assigned randomly. While accuracy measures the overall correctness of the classifier, it does not distinguish between false positive errors and false negative errors. Some applications may be more sensitive to false negatives than false positives, or vice versa. Furthermore, Accuracy is not an informative metric if the proportions of the classes are skewed in population. For example, a classifier that predicts whether or not credit card transactions are fraudulent may be more sensitive to false negatives than false positives. That is, most transactions are legitimate, accuracy is not an appropriate metric for this problem. A classifier that always predicts transactions are legitimate could have a high accuracy score, but would not be useful. For these reasons, classifiers are often evaluated using two additional measures called ***PRECISION*** and ***RECALL***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFMlmLmGjMbh",
        "colab_type": "text"
      },
      "source": [
        "# ***Precision and Recall***\n",
        "Precision: The precision is the fraction of positive predictions that are correct. In our case, precision if the fraction of messages classified as spam that are actually spam. Given by ration: ***P=TP/(TP+FP)***, TP=True Positive, FP=False Positive.\n",
        "Recall: Recall is the fraction of the truly positive instances that the classifier recognizes. In our case, recall is fraction of spam messages that were truly classified as spam. Given by ratio: R=TP/(TP+FN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDe8N1EHBi3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "20734e2f-33db-4c0f-97d1-af20c9188708"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model.logistic import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import precision_score, recall_score, make_scorer,f1_score #get precision and recall\n",
        "#we had imported our csv earlier so no need to import it again. However, in a new notebook or program, you need to import it.\n",
        "X_train_raw,X_test_raw,y_train,y_test=train_test_split(df[1],df[0])\n",
        "vectorizer=TfidfVectorizer()\n",
        "X_train=vectorizer.fit_transform(X_train_raw)\n",
        "X_test=vectorizer.transform(X_test_raw)\n",
        "classifier=LogisticRegression()\n",
        "classifier.fit(X_train,y_train)\n",
        "precision_scorer = make_scorer(precision_score, pos_label='spam')\n",
        "precision=cross_val_score(classifier,X_train,y_train,cv=5,scoring=precision_scorer)\n",
        "print(\"Precision mean: \",np.mean(precision))\n",
        "print(\"Precision: \",precision)\n",
        "recall_scorer = make_scorer(recall_score, pos_label='spam')\n",
        "recall=cross_val_score(classifier,X_train,y_train,cv=7,scoring=recall_scorer)\n",
        "print(\"Recall mean: \",np.mean(recall))\n",
        "print(\"Recall: \",recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision mean:  0.9923076923076923\n",
            "Precision:  [1.         1.         0.96153846 1.         1.        ]\n",
            "Recall mean:  0.6648583484026522\n",
            "Recall:  [0.65384615 0.64102564 0.66666667 0.70512821 0.6835443  0.59493671\n",
            " 0.70886076]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgyv5h3ZplXh",
        "colab_type": "text"
      },
      "source": [
        "Our classifier's precision is 0.9869; almost all the messages that were predicted as spam were actually spam.\n",
        "It's recall is lower i.e it incorrectly classified 31%(1-0.6992) of spam messages as ham."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS-aBvRRhPlW",
        "colab_type": "text"
      },
      "source": [
        "# Calculating the F1 measure.\n",
        "The F1 measure is the harmonic mean, or weighted average, of the precision and recall scores. Also called the f-measure or the f-score. \n",
        "Formula: F1=2*(PR/(P+R)), P=Precision, R=Recall\n",
        "The F1=measure penalizes classifiers with imbalanced precision and recall scores, like the trivial classifier that always predicts positive class. A model with perfect precision and recall scores will achieve an F1-score of 1. A model with a perfect precision and a recall of 0 will achieve a f1-score of 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6bqjdMthORc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6cadc37f-4bd9-4886-9b8c-43868bbfaaae"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_scorer=make_scorer(f1_score, pos_label='spam')\n",
        "f1=cross_val_score(classifier,X_train,y_train,cv=5,scoring=f1_scorer)\n",
        "print(\"F1 Score Mean: \",np.mean(f1))\n",
        "print(\"F1 Scores: \",f1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score Mean:  0.7866178760342091\n",
            "F1 Scores:  [0.77777778 0.79781421 0.79787234 0.76404494 0.79558011]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM-c4ko7fHTs",
        "colab_type": "text"
      },
      "source": [
        "# ***Tuning models with Grid Search***\n",
        "Hyperparamters are parameters of the model that are not learned. For example, hyperparameters of our logistic regression SMS classifier include the value of the regularization term and thresholds used to remove words that appear too frequently or infrequently.\n",
        "Grid Search takes a set of possible values for each hyperparameter that should be tuned, and evaluates the model trained on each element of Cartesian product of sets. That is, Grid Search is an exhaustive search that trains and evaluates the model for each possible combination of hyperparamter values supplied by the developer. A con of grid search is its compuational cost.\n",
        "\n",
        "GridSearchCV() takes an estimator, a parameter space, and a performance measure. The argument n_jobs specifies the maximum number of concurrent jobs; set n_jobs=-1 to use all CPU cores. Note that fit() must be called in Python main block in order to fork additional processes; this example must be executed as a script, an not as an interactive interpreter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BkpWKwBfR0g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "7531180c-c263-4aa3-9b40-8b28072d72bb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model.logistic import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import precision_score, recall_score, make_scorer,f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline=Pipeline([('vect',TfidfVectorizer(stop_words='english')),('clf',LogisticRegression())])\n",
        "\n",
        "parameters={\n",
        "    'vect__max_df':(0.25,0.5,0.75),          #all the keys contain double underscore(__) as you can see, single underscore will give an error.\n",
        "    'vect__stop_words':('english','None'),\n",
        "    'vect__max_features':(2500,5000,1000, None),\n",
        "    'vect__ngram_range':((1,1),(1,2)),\n",
        "    'vect__use_idf':(True,False),\n",
        "    'vect__norm':('l1','l2'),\n",
        "    'clf__penalty':('l1','l2'),\n",
        "    'clf__C':(0.01,0.1,1,10),\n",
        "\n",
        "}\n",
        "if __name__==\"__main__\":\n",
        "  grid_search=GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy',cv=3)\n",
        "  X,y=df[1],df[0]\n",
        "  X_train,X_test,y_train,y_test=train_test_split(X,y)\n",
        "  grid_search.fit(X_train,y_train)\n",
        "  print(\"Best score: %0.3f\" %grid_search.best_score_)\n",
        "  print(\"Best scores parameters set: \")\n",
        "  best_parameters=grid_search.best_estimator_.get_params() #The .best_estimator_ attribute is an instance of the specified model type,\n",
        "  # which has the 'best' combination of given parameters from the param_grid. \n",
        "  for param_name in sorted(parameters.keys()):\n",
        "    print('\\t%s: %r'%(param_name,best_parameters[param_name]))\n",
        "  predictions=grid_search.predict(X_test)\n",
        "  print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
        "  print(\"Precision: \", precision_score(y_test, predictions,pos_label='spam'))\n",
        "  print(\"Recall: \", recall_score(y_test, predictions,pos_label='spam'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1536 candidates, totalling 4608 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=-1)]: Done 764 tasks      | elapsed:   30.0s\n",
            "[Parallel(n_jobs=-1)]: Done 1764 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 3164 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 4608 out of 4608 | elapsed:  3.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.980\n",
            "Best scores parameters set: \n",
            "\tclf__C: 10\n",
            "\tclf__penalty: 'l2'\n",
            "\tvect__max_df: 0.25\n",
            "\tvect__max_features: 1000\n",
            "\tvect__ngram_range: (1, 2)\n",
            "\tvect__norm: 'l2'\n",
            "\tvect__stop_words: 'english'\n",
            "\tvect__use_idf: False\n",
            "Accuracy:  0.9834888729361091\n",
            "Precision:  0.9702380952380952\n",
            "Recall:  0.9005524861878453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXpFHJgJsWWu",
        "colab_type": "text"
      },
      "source": [
        "Optimizing the values of the hyperparameters has improved our model's recall score on the test set."
      ]
    }
  ]
}